{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "License Plate Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/Number-plate-detection/blob/master/License%20Plate%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IdLWMJPXmGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,/;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kagglesdsdata/datasets/36674/55880/Indian_Number_plates.json?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1575899280&Signature=pfqwJEhrAlwOVOclYCDODMMHBN8S9OO5PFhp0D9WOiX%2FT%2Bfm8x%2BzOFNGD7Iw%2BV%2BqCKHrh%2Bq769FGFP8%2BlvfK8alwQicZDoNj3NvDmoGFH6IgDsRKoWNtZfuYMrkOdbxs4%2FIAKm4ZlyR9uxUxnCbKTOA3RAKbdZL0%2BflDBUXcO%2F8LLuVoYVS5ff7QVc%2B8G1Qjt1JTv2mGfpIctRSW3UfyhsU%2BQelptCDhS1NxQmjJm7V3pHkUtdM4sTohrSQs7feXPKcHRaWH2EpFy0xKG7T5aXpXFhwFwIaiUJtxRlwSxAaeom3ne4a8XO5hNM%2BL5ljM4Tva0yhEf%2FZsXGEcMULekQ%3D%3D&response-content-disposition=attachment%3B+filename%3DIndian_Number_plates.json\" -O \"Indian_Number_plates.json\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDfkfPk_Xsjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/openalpr/benchmarks.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "4dhnn5yVXhpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Input, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEU2fk9OXhpc",
        "colab_type": "text"
      },
      "source": [
        "# Methods\n",
        "There are three steps in this notebook. The first one is getting the data from the given JSON file. The second one is creating a usable CSV from it. And the third one is creating and training a deep CNN for license plate detection. I used Keras to make the CNN part simpler.\n",
        "\n",
        "## The Dataset\n",
        "The dataset isn't similar to those that I saw before. It comes with a JSON format with multiline records in it. The two main elemnts are *content* and *annotation*. *content* contains links to images and *annotation* contains some information about the respected image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RbZyNNLMXhpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_json(\"/kaggle/input/vehicle-number-plate-detection/Indian_Number_plates.json\", lines=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TsQQ3emhXhpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"Indian Number Plates\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkjK8g4cXhp2",
        "colab_type": "text"
      },
      "source": [
        "I wrote a simple script to download and save all images to a directory while recording their respected annotation information to a dictionary. The informations that I recorded were `image_width`, `image_height`, x and y coordinates of top left corner and x and y coordinates of bottom right corner of the bounding box (`[top_x, top_y, bottom_x, bottom_y]`).\n",
        "\n",
        "At first, I thought all images are JPEG. However, a quick inspection of downloaded images showed that this assumption was wrong. Some of the images are GIF. So, before saving images, I converted them to JPEG images with three (RGB) channels by using `PIL.Image` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BXHGFDFdXhp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dict()\n",
        "dataset[\"image_name\"] = list()\n",
        "dataset[\"image_width\"] = list()\n",
        "dataset[\"image_height\"] = list()\n",
        "dataset[\"top_x\"] = list()\n",
        "dataset[\"top_y\"] = list()\n",
        "dataset[\"bottom_x\"] = list()\n",
        "dataset[\"bottom_y\"] = list()\n",
        "\n",
        "counter = 0\n",
        "for index, row in df.iterrows():\n",
        "    img = urllib.request.urlopen(row[\"content\"])\n",
        "    img = Image.open(img)\n",
        "    img = img.convert('RGB')\n",
        "    img.save(\"Indian Number Plates/licensed_car{}.jpeg\".format(counter), \"JPEG\")\n",
        "    \n",
        "    dataset[\"image_name\"].append(\"licensed_car{}\".format(counter))\n",
        "    \n",
        "    data = row[\"annotation\"]\n",
        "    \n",
        "    dataset[\"image_width\"].append(data[0][\"imageWidth\"])\n",
        "    dataset[\"image_height\"].append(data[0][\"imageHeight\"])\n",
        "    dataset[\"top_x\"].append(data[0][\"points\"][0][\"x\"])\n",
        "    dataset[\"top_y\"].append(data[0][\"points\"][0][\"y\"])\n",
        "    dataset[\"bottom_x\"].append(data[0][\"points\"][1][\"x\"])\n",
        "    dataset[\"bottom_y\"].append(data[0][\"points\"][1][\"y\"])\n",
        "    \n",
        "    counter += 1\n",
        "print(\"Downloaded {} car images.\".format(counter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "854d0AjKXhqE",
        "colab_type": "text"
      },
      "source": [
        "After that, I created a Dataframe object from the dictionary that I've mentioned before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-dz-CO5OXhqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(dataset)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtrKAciYXhqT",
        "colab_type": "text"
      },
      "source": [
        "Then, I saved it for later more simpler use. You can also download this CSV from the output section of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_A5h3_HfXhqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"indian_license_plates.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_48anGn3Xhqg",
        "colab_type": "text"
      },
      "source": [
        "Next, I read the previously recorded CSV file and cropped some information from it. Since I fixed the image width and height to 128px by 128px, those columns were not necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "mZ_zv5aEXhqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"indian_license_plates.csv\")\n",
        "df[\"image_name\"] = df[\"image_name\"] + \".jpeg\"\n",
        "df.drop([\"image_width\", \"image_height\"], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgyr2jqgXhqr",
        "colab_type": "text"
      },
      "source": [
        "I picked five random records from the dataframe for a later visiual inspection of predictions. I dropped these records from the original dataframe by aiming to prevent the model to be trained on them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "keZ95fx8Xhqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lucky_test_samples = np.random.randint(0, len(df), 5)\n",
        "reduced_df = df.drop(lucky_test_samples, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KMqggndjXhq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WIDTH = 224\n",
        "HEIGHT = 224\n",
        "CHANNEL = 3\n",
        "\n",
        "def show_img(index):\n",
        "    image = cv2.imread(\"Indian Number Plates/\" + df[\"image_name\"].iloc[index])\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, dsize=(WIDTH, HEIGHT))\n",
        "\n",
        "    tx = int(df[\"top_x\"].iloc[index] * WIDTH)\n",
        "    ty = int(df[\"top_y\"].iloc[index] * HEIGHT)\n",
        "    bx = int(df[\"bottom_x\"].iloc[index] * WIDTH)\n",
        "    by = int(df[\"bottom_y\"].iloc[index] * HEIGHT)\n",
        "\n",
        "    image = cv2.rectangle(image, (tx, ty), (bx, by), (0, 0, 255), 1)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ4Mkd9BXhrC",
        "colab_type": "text"
      },
      "source": [
        "Here, you can see a sample image from the dataset with a bounding box over the license plate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3P6FdZfrXhrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M1iH4sWXhrM",
        "colab_type": "text"
      },
      "source": [
        "I created an `ImageDataGenerator` object from Keras to load batches of images to memory. This process is necessary because we do not have infinite memory in both RAM and GPU RAM. I splitted the data into two with a batch size of 32 images. One for training (80% of the data) and one for validation (20% of the data) during training. Validation is important to see if the model overfit to the training data.\n",
        "\n",
        "## The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XkMfV-pBXhrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    reduced_df,\n",
        "    directory=\"Indian Number Plates/\",\n",
        "    x_col=\"image_name\",\n",
        "    y_col=[\"top_x\", \"top_y\", \"bottom_x\", \"bottom_y\"],\n",
        "    target_size=(WIDTH, HEIGHT),\n",
        "    batch_size=32, \n",
        "    class_mode=\"other\",\n",
        "    subset=\"training\")\n",
        "\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    reduced_df,\n",
        "    directory=\"Indian Number Plates/\",\n",
        "    x_col=\"image_name\",\n",
        "    y_col=[\"top_x\", \"top_y\", \"bottom_x\", \"bottom_y\"],\n",
        "    target_size=(WIDTH, HEIGHT),\n",
        "    batch_size=32, \n",
        "    class_mode=\"other\",\n",
        "    subset=\"validation\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hByxdZhyXhrY",
        "colab_type": "text"
      },
      "source": [
        "I created a relatively \"not so deep\" convolutional neural network. It have 8 convolutinal layers with 4 max pool layers and a fully connected network with 2 hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CfPl0A67Xhrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(VGG16(weights=\"imagenet\", include_top=False, input_shape=(HEIGHT, WIDTH, CHANNEL)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(4, activation=\"sigmoid\"))\n",
        "\n",
        "model.layers[-6].trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AroPTf3TXhrj",
        "colab_type": "text"
      },
      "source": [
        "To find the minimum amount of step count to cover all the batches, the following equations are necessary. Mathematically;\n",
        "\n",
        "$$\n",
        "\\text{Step size} = \\lceil \\frac{\\text{Number of elements}}{\\text{Batch Size}} \\rceil\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XOcWKrRAXhrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEP_SIZE_TRAIN = int(np.ceil(train_generator.n / train_generator.batch_size))\n",
        "STEP_SIZE_VAL = int(np.ceil(validation_generator.n / validation_generator.batch_size))\n",
        "\n",
        "print(\"Train step size:\", STEP_SIZE_TRAIN)\n",
        "print(\"Validation step size:\", STEP_SIZE_VAL)\n",
        "\n",
        "train_generator.reset()\n",
        "validation_generator.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HImk9bGWXhry",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJd6ZS-uXhr2",
        "colab_type": "text"
      },
      "source": [
        "I used Adam to optimize the weights and mean squared error as my loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vtOPPKmxXhr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.0005)\n",
        "model.compile(optimizer=adam, loss=\"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GtrHd2skXhr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=STEP_SIZE_VAL,\n",
        "    epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4yHY8BMZXhsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCAEUCFVXhsO",
        "colab_type": "text"
      },
      "source": [
        "The model's success over the validation data is 80%. However, you can see that from the above figure, the training is stopped after 30th epoch. This may because of the low number of training samples or my model is not capable of learning such data. If you have an idea, please comment below.\n",
        "\n",
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BnLUt9WbXhsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate_generator(validation_generator, steps=STEP_SIZE_VAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwOgsbOJXhsd",
        "colab_type": "text"
      },
      "source": [
        "Remember that, we had picked five lucky test samples for visiual inspection. Here they are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1OIskjAbXhsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, row in df.iloc[lucky_test_samples].iterrows():    \n",
        "    img = cv2.resize(cv2.imread(\"Indian Number Plates/\" + row[0]) / 255.0, dsize=(WIDTH, HEIGHT))\n",
        "    y_hat = model.predict(img.reshape(1, WIDTH, HEIGHT, 3)).reshape(-1) * WIDTH\n",
        "    \n",
        "    xt, yt = y_hat[0], y_hat[1]\n",
        "    xb, yb = y_hat[2], y_hat[3]\n",
        "    \n",
        "    img = cv2.cvtColor(img.astype(np.float32), cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.rectangle(img, (xt, yt), (xb, yb), (0, 0, 255), 1)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWa04sbuXhsi",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "The model defined above is a very simple toy model. The training is straightforward and tests may not be reliable since the dataset is so small. However, it proves a concept that you can find plates from images with a simple CNN. This network may be used as a part of other more complicated networks.\n",
        "\n",
        "Thank you :)"
      ]
    }
  ]
}